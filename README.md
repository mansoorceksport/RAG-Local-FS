# ğŸŸï¸ FC Barcelona HR RAG - Local Files, No Database

*A lightweight Retrieval-Augmented Generation system using Markdown files as knowledge base.*

Welcome to the **FC Barcelona HR RAG System** - a simple, self-contained Retrieval-Augmented Generation (RAG) project that loads Markdown-based HR/player records directly from the filesystem into memory.

No database.
No vector DB.
No embeddings.
Just pure **local markdown â†’ dictionary â†’ context injection â†’ LLM**.

Perfect for small projects, demo apps, or experimenting with RAG fundamentals.

---

## ğŸš€ Features

### âœ” Local File-Based Knowledge Store

* HR/player records stored as `.md` files
* Loaded automatically into a Python `dict`
* Easy to modify, easy to version-control

### âœ” Context-Injection RAG

* User query analyzed for keyword matches
* Relevant markdown snippets injected into system prompt
* LLM answers with higher accuracy using only local data

### âœ” OpenAI API Integration

* Uses `gpt-4.1-nano` for fast + cheap responses
* System prompt built specifically around **FC Barcelona** employees

### âœ” Simple Gradio Chat UI

* Full chat interface
* Local browser launch
* Debug logs enabled

### âœ” Fully Offline Knowledge

* No vectors
* No external DB
* No third-party storage
* Everything lives inside `data/employees/*.md`

---

## ğŸ“ Project Structure

```
/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ employees/
â”‚       â”œâ”€â”€ <employee1>.md
â”‚       â”œâ”€â”€ <employee2>.md
â”‚       â””â”€â”€ ...
â”‚
â”œâ”€â”€ synthetic_data_generator.py   (optional, if you generate fake players)
â”œâ”€â”€ main.py                       (your main RAG chat app)
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ§  How It Works

### 1ï¸âƒ£ Load all `.md` files into memory

```python
knowledge = load_markdown_files()
```

Each employee record becomes a key-value entry:

```
{name: markdown_content}
```

### 2ï¸âƒ£ Detect keywords in user query

```python
get_relevant_context(message)
```

If words from the question match employee names â†’ relevant markdown is returned.

### 3ï¸âƒ£ Inject context into system prompt

```python
system_message = SYSTEM_PREFIX + additional_context(message)
```

### 4ï¸âƒ£ Chat model replies with improved accuracy

```python
openai.chat.completions.create(...)
```

### 5ï¸âƒ£ All wrapped in a clean Gradio UI

```python
gr.ChatInterface(...).launch(inbrowser=True)
```

---

## â–¶ï¸ Running the Project

### **1. Install dependencies**

```bash
pip install -r requirements.txt
```

### **2. Add your OpenAI API key**

Create a `.env` file:

```
OPENAI_API_KEY=your_key_here
```

### **3. Put employee/player files into**

```
data/employees/*.md
```

### **4. Run the app**

```bash
python main.py
```

This opens the Gradio chat UI in your browser.

---

## âœï¸ Example Query

> "What is the salary of Pedri?"
> "How did JoÃ£o FÃ©lix perform in 2022?"
> "Tell me about the injuries of Ansu Fati."

The system will automatically:
âœ” extract keywords
âœ” search local markdown files
âœ” inject only relevant context
âœ” respond like an FC Barcelona HR expert

---

## ğŸ›  Tech Stack

* **Python 3.10+**
* **OpenAI API**
* **Gradio**
* **dotenv**
* **Local markdown RAG** (no vector DB)

---

## ğŸ’¡ Future Enhancements

If you want to expand the project, here are natural next steps:

* Add embeddings + semantic search
* Add synthetic player generator (already done!)
* Add evaluation for RAG accuracy
* Add API endpoint (FastAPI)
* Add frontend widget for websites
* Add player stats parser (goals/assists/etc.)

---

## âš½ Final Words

This project is intentionally **simple**, **transparent**, and **educational** - but powerful enough to answer structured questions about FC Barcelona players using only local markdown files.

If the club ever needs a *personal AI sporting director*, youâ€™re already halfway there. ğŸ˜„
